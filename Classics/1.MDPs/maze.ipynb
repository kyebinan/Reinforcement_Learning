{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a : MDP formulation\n",
    "\n",
    "We propose the following MDP formulation: \n",
    "\n",
    "#### State space $\\mathcal{S}$\n",
    "The space of state is simply the cartesian product of all the squares of the grid accessible by the player times all the squares of the grid accessible by the minotaur or the whole grid, hence :\n",
    "$$\\mathcal{s} = \\textrm{41 $\\times$ 56 states}$$\n",
    "\n",
    "#### Action Space $\\mathcal{A}$\n",
    "This are all the possible actions in the MDP\n",
    "\n",
    "$$\\mathcal{A} = \\lbrace \\textrm{up, down, right, left, stay}\\rbrace$$\n",
    "\n",
    "#### Transition Probabilities $\\mathbb{P}$\n",
    "\n",
    "- If at position $c$ taking action $a$ does not lead to a wall or an obstacle or being caught by the minotaur but to another position $c'$, then $\\mathbb{P}(c' \\vert c, a) = 1$. \n",
    "- If at  position  $c$ taking  move $a$ leads to a wall or an obstacle, the player remains in his position $c$, then $\\mathbb{P}(c \\vert c, a) = 1$.\n",
    "- For the Minotaur the transition probabilities $\\mathbb{P}(c' \\vert c, a) = 1/4$ for each move or $1/3$, $1/2$ if the minotaur is at one border or two border.\n",
    "\n",
    "Hence the Transition probabilies is $\\mathbb{P}(s' \\vert s, a) = 1/4$ for each move or $1/3$, $1/2$ if the minotaur is at one border or two border.\n",
    "\n",
    "#### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles.    \n",
    "   - If at state $s$, taking action $a$, leads to a wall or an obstacle then $r(s,a) = -20$\n",
    "   - If at state $s$, taking action $a$, leads to being caught then the reward $r(s,a) = -75$\n",
    "   - If at state $s$, taking action $a$, leads to some other position in the maze that is not the exit nor a wall nor an obstacle, then $r(s, a) = -5$. \n",
    "   - If at state $s$, taking action $a$, leads to the exit then $r(s ,a) = 10$.\n",
    "\n",
    "#### Discount Factor $\\mathcal{\\Lambda}$\n",
    "The discount factor would be  $\\lambda^{(t-1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import main \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with the convention \n",
    "# 0 = empty cell\n",
    "# 1 = obstacle\n",
    "# 2 = exit of the Maze\n",
    "\n",
    "maze = np.array ([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0 ,0, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]\n",
    "])\n",
    "\n",
    "utils.draw_maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = main.SimpleMaze(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "start_agent     = (0,0)\n",
    "horizon = 25\n",
    "V, policy = main.Algorithm.dynamic_programming(env, horizon, env.rewards, env.transition_probabilities)\n",
    "path, victory, policy = env.simulateDynProg(start_agent, V, policy)\n",
    "print(victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.animate_solution(env.maze, path, policy, env, 'DynProg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a : MDP formulation\n",
    "\n",
    "We propose the following MDP formulation: \n",
    "\n",
    "#### State space $\\mathcal{S}$\n",
    "The space of state is simply the cartesian product of all the squares of the grid accessible by the player times all the squares of the grid accessible by the minotaur or the whole grid, hence :\n",
    "$$\\mathcal{s} = \\textrm{41 $\\times$ 56 states}$$\n",
    "\n",
    "#### Action Space $\\mathcal{A}$\n",
    "This are all the possible actions in the MDP\n",
    "\n",
    "$$\\mathcal{A} = \\lbrace \\textrm{up, down, right, left, stay}\\rbrace$$\n",
    "\n",
    "#### Transition Probabilities $\\mathbb{P}$\n",
    "\n",
    "- If at position $c$ taking action $a$ does not lead to a wall or an obstacle or being caught by the minotaur but to another position $c'$, then $\\mathbb{P}(c' \\vert c, a) = 1$. \n",
    "- If at  position  $c$ taking  move $a$ leads to a wall or an obstacle, the player remains in his position $c$, then $\\mathbb{P}(c \\vert c, a) = 1$.\n",
    "- For the Minotaur the transition probabilities $\\mathbb{P}(c' \\vert c, a) = 1/4$ for each move or $1/3$, $1/2$ if the minotaur is at one border or two border.\n",
    "\n",
    "Hence the Transition probabilies is $\\mathbb{P}(s' \\vert s, a) = 1/4$ for each move or $1/3$, $1/2$ if the minotaur is at one border or two border.\n",
    "\n",
    "#### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles.    \n",
    "   - If at state $s$, taking action $a$, leads to a wall or an obstacle then $r(s,a) = -20$\n",
    "   - If at state $s$, taking action $a$, leads to being caught then the reward $r(s,a) = -75$\n",
    "   - If at state $s$, taking action $a$, leads to some other position in the maze that is not the exit nor a wall nor an obstacle, then $r(s, a) = -5$. \n",
    "   - If at state $s$, taking action $a$, leads to the exit then $r(s ,a) = 10$.\n",
    "\n",
    "#### Discount Factor $\\mathcal{\\Lambda}$\n",
    "The discount factor would be  $\\lambda^{(t-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Value Iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment maze\n",
    "env = main.Maze(maze)\n",
    "# env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_agent     = (6,3)\n",
    "start_minotaur  = (2,3)\n",
    "gamma = 0.9\n",
    "epsilon = 0.3\n",
    "\n",
    "V, policy = main.value_iteration(env, gamma, epsilon, env.rewards, env.transition_probabilities, env.n_states)\n",
    "\n",
    "path, victory, policy = env.simulateValIter(start_agent, start_minotaur, V, policy)\n",
    "print(victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
